{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(gpu_options = \n",
    "                         tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "# device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self,\n",
    "                loss_object,\n",
    "                optimizer,\n",
    "                train_loss,\n",
    "                train_metric,\n",
    "                test_loss,\n",
    "                test_metric):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32,3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='relu')\n",
    "        \n",
    "        self.loss_object = loss_object\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loss = train_loss\n",
    "        self.train_metric = train_metric\n",
    "        self.test_loss = test_loss\n",
    "        self.test_metric = test_metric\n",
    "    \n",
    "    def nn_model(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.nn_model(images)\n",
    "            loss = self.loss_object(labels, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.train_loss(loss)\n",
    "        self.train_metric(labels, predictions)\n",
    "        \n",
    "    @tf.function\n",
    "    def test_step(self, images, labels):\n",
    "        predictions = self.nn_model(images)\n",
    "        t_loss = self.loss_object(labels, predictions)\n",
    "        self.test_loss(t_loss)\n",
    "        self.test_metric(labels, predictions)\n",
    "        \n",
    "    def fit(self, train, test, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train:\n",
    "                self.train_step(tf.cast(images, tf.float32), labels)\n",
    "            for test_images, test_labels in test:\n",
    "                self.test_step(tf.cast(test_images, tf.float32), test_labels)\n",
    "            template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n",
    "            print(template.format(epoch+1,\n",
    "                                 self.train_loss.result(),\n",
    "                                 self.train_metric.result()*100,\n",
    "                                 self.test_loss.result(),\n",
    "                                 self.test_metric.result()*100))\n",
    "            \n",
    "            self.train_loss.reset_states()\n",
    "            self.train_metric.reset_states()\n",
    "            self.test_loss.reset_states()\n",
    "            self.test_metric.reset_states()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0319 03:11:43.837049 21900 base_layer.py:1790] Layer conv2d_4 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 14.453303081766764, Accuracy: 9.875, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 2, Loss: 14.527145713806153, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 3, Loss: 14.527145721435547, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 4, Loss: 14.527145711771647, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 5, Loss: 14.527145702107747, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 6, Loss: 14.527145721944173, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 7, Loss: 14.527145714823405, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 8, Loss: 14.527145719909669, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 9, Loss: 14.527145720418295, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n",
      "Epoch 10, Loss: 14.52714572092692, Accuracy: 9.871666666666666, Test Loss: 14.539645365632762, Test Accuracy: 9.8\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = MyModel(loss_object = loss_object,\n",
    "                optimizer = optimizer,\n",
    "                train_loss = train_loss,\n",
    "                train_metric = train_metric,\n",
    "                test_loss = test_loss,\n",
    "                test_metric = test_metric)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "model.fit(train = train_ds,\n",
    "          test = test_ds,\n",
    "          epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
